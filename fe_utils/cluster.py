# AUTOGENERATED! DO NOT EDIT! File to edit: 00_cluster.ipynb (unless otherwise specified).

__all__ = ['load_embedding', 'BayesClusterTrainer']

# Cell

def load_embedding(path):
    """
    dataloader for saved embeddings. Load from numpy file
    """
    emb = np.load(path)

    return emb


# Cell

from hyperopt import fmin, tpe, space_eval

class BayesClusterTrainer():
    """
    A trainer for cluster optimization runs
    Inputs:
        `space`: `dict` containing relevant parameter spaces for `hdbscan` and `umap`

    """

    def __init__(self, space, cost_fn_params, embeddings, labels, *args, **kwargs):
        self.space = space
        self.cost_fn_params = cost_fn_params

        self.embeddings = embeddings
        self.labels = labels

        self.logs = []

        self.run = dict()

    def generate_clusters(self, embeddings,
                        min_cluster_size,
                        cluster_selection_epsilon,
                        cluster_selection_method,
                        metric,
                        n_neighbors,
                        n_components,
                        random_state = 42):
        """
        Generate HDBSCAN cluster object after reducing embedding dimensionality with UMAP
        """

        umap_embeddings = (umap.UMAP(n_neighbors=n_neighbors,
                                    n_components=n_components,
                                    metric='cosine',
                                    random_state=random_state)
                                    .fit_transform(embeddings))

        clusters = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,
                                   metric=metric, cluster_selection_epsilon = cluster_selection_epsilon,
                                   cluster_selection_method=cluster_selection_method,
                                   gen_min_span_tree=True).fit(umap_embeddings)

        return clusters

    def objective(self, params, embeddings, labels):
        """
        Objective function for hyperopt to minimize, which incorporates constraints
        on the number of clusters we want to identify
        """

        clusters = generate_clusters(embeddings,
                                     n_neighbors = params['n_neighbors'],
                                     n_components = params['n_components'],
                                     min_cluster_size = params['min_cluster_size'],
                                     cluster_selection_epsilon = params['cluster_selection_epsilon'],
                                     metric = params['metric'],
                                     cluster_selection_method = params['cluster_selection_method'],
                                     random_state = 42)

        cost = score_clusters(clusters, y)


        pprint(params)

        loss = cost

        return {'loss': loss, 'status': STATUS_OK}


    def score_clusters(self, clusters, y):
        """
        Returns the label count and cost of a given cluster supplied from running hdbscan
        """
        penalty = (clusters.labels_ == -1).sum() / len(clusters.labels_)
        pers = clusters.cluster_persistence_.mean(0)
        val = clusters.relative_validity_
        outlier = clusters.outlier_scores_.mean(0)
        prob = clusters.probabilities_.mean(0)

        #cluster_size = len(np.unique(clusters.labels_))

        score = -1*(val + prob + pers) + (penalty + outlier)
        score = score/5

        fns = [adjusted_rand_score, homogeneity_completeness_v_measure, homogeneity_score, v_measure_score, completeness_score, adjusted_mutual_info_score]

        print(f"SCORE: {score}")
        for fn in fns:
            print(f"{fn.__name__} : {fn(clusters.labels_, y)}")
        print("-"*20)

        return score


    def train(self, max_evals=100, algo=tpe.suggest):
        """
        Perform bayesian search on hyperopt hyperparameter space to minimize objective function
        """

        trials = Trials()
        fmin_objective = partial(self.objective, embeddings=self.embeddings, labels=self.labels)
        best = fmin(fmin_objective,
                    space = self.space,
                    algo=algo,
                    max_evals=max_evals,
                    trials=trials)

        best_params = space_eval(self.space, best)
        print ('best:')
        print (best_params)
        print("-"*20)
        print("-"*20)

        best_clusters = generate_clusters(self.embeddings,
                                         n_neighbors = best_params['n_neighbors'],
                                         n_components = best_params['n_components'],
                                         min_cluster_size = best_params['min_cluster_size'],
                                         cluster_selection_epsilon = best_params['cluster_selection_epsilon'],
                                         metric = best_params['metric'],
                                         cluster_selection_method = best_params['cluster_selection_method']
                                         )

        return best_params, best_clusters, trials

    def fit(self):
        print('*' * 10)
        print('TRAINING NOW!')
        print('*' * 10)
