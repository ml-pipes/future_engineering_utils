{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fe_utils.cluster\n",
    "> module for clustering optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import*\n",
    "from functools import partial\n",
    "import hdbscan\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "from hyperopt import Trials\n",
    "from hyperopt import STATUS_OK\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import homogeneity_completeness_v_measure\n",
    "from sklearn.metrics.cluster import homogeneity_score, v_measure_score, silhouette_score \n",
    "from sklearn.metrics.cluster import completeness_score, adjusted_mutual_info_score\n",
    "import time\n",
    "import umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def load_embedding(path):\n",
    "    \"\"\"\n",
    "    dataloader for saved embeddings. Load from numpy file\n",
    "    \"\"\"\n",
    "    emb = np.load(path)\n",
    "    \n",
    "    return emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "\n",
    "class BayesClusterTrainer():\n",
    "    \"\"\"\n",
    "    A trainer for cluster optimization runs\n",
    "    Inputs:\n",
    "        `space`: `dict` containing relevant parameter spaces for `hdbscan` and `umap`\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, space, cost_fn_params, embeddings, labels, *args, **kwargs):\n",
    "        self.space = space\n",
    "        self.cost_fn_params = cost_fn_params\n",
    "\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "        self.logs = []\n",
    "\n",
    "        self.run = dict()\n",
    "\n",
    "    def generate_clusters(self, embeddings,\n",
    "                        min_cluster_size,\n",
    "                        cluster_selection_epsilon,\n",
    "                        cluster_selection_method,\n",
    "                        metric,\n",
    "                        n_neighbors,\n",
    "                        n_components, \n",
    "                        random_state = 42):\n",
    "        \"\"\"\n",
    "        Generate HDBSCAN cluster object after reducing embedding dimensionality with UMAP\n",
    "        \"\"\"\n",
    "    \n",
    "        umap_embeddings = (umap.UMAP(n_neighbors=n_neighbors, \n",
    "                                    n_components=n_components, \n",
    "                                    metric='cosine', \n",
    "                                    random_state=random_state)\n",
    "                                    .fit_transform(embeddings))\n",
    "\n",
    "        clusters = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,\n",
    "                                   metric=metric, cluster_selection_epsilon = cluster_selection_epsilon,\n",
    "                                   cluster_selection_method=cluster_selection_method,\n",
    "                                   gen_min_span_tree=True).fit(umap_embeddings)\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def objective(self, params, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Objective function for hyperopt to minimize, which incorporates constraints\n",
    "        on the number of clusters we want to identify\n",
    "        \"\"\"\n",
    "    \n",
    "        clusters = generate_clusters(embeddings, \n",
    "                                     n_neighbors = params['n_neighbors'], \n",
    "                                     n_components = params['n_components'], \n",
    "                                     min_cluster_size = params['min_cluster_size'],\n",
    "                                     cluster_selection_epsilon = params['cluster_selection_epsilon'],\n",
    "                                     metric = params['metric'],\n",
    "                                     cluster_selection_method = params['cluster_selection_method'],\n",
    "                                     random_state = 42)\n",
    "\n",
    "        cost = score_clusters(clusters, y)\n",
    "\n",
    "\n",
    "        pprint(params)\n",
    "\n",
    "        loss = cost\n",
    "\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "    def score_clusters(self, clusters, y):\n",
    "        \"\"\"\n",
    "        Returns the label count and cost of a given cluster supplied from running hdbscan\n",
    "        \"\"\"\n",
    "        penalty = (clusters.labels_ == -1).sum() / len(clusters.labels_)\n",
    "        pers = clusters.cluster_persistence_.mean(0)\n",
    "        val = clusters.relative_validity_\n",
    "        outlier = clusters.outlier_scores_.mean(0)\n",
    "        prob = clusters.probabilities_.mean(0)\n",
    "\n",
    "        #cluster_size = len(np.unique(clusters.labels_))\n",
    "\n",
    "        score = -1*(val + prob + pers) + (penalty + outlier)\n",
    "        score = score/5                                             \n",
    "\n",
    "        fns = [adjusted_rand_score, homogeneity_completeness_v_measure, homogeneity_score, v_measure_score, completeness_score, adjusted_mutual_info_score]\n",
    "\n",
    "        print(f\"SCORE: {score}\")\n",
    "        for fn in fns:\n",
    "            print(f\"{fn.__name__} : {fn(clusters.labels_, y)}\")                                            \n",
    "        print(\"-\"*20)\n",
    "\n",
    "        return score\n",
    "\n",
    "\n",
    "    def train(self, max_evals=100, algo=tpe.suggest):\n",
    "        \"\"\"\n",
    "        Perform bayesian search on hyperopt hyperparameter space to minimize objective function\n",
    "        \"\"\"\n",
    "    \n",
    "        trials = Trials()\n",
    "        fmin_objective = partial(self.objective, embeddings=self.embeddings, labels=self.labels)\n",
    "        best = fmin(fmin_objective, \n",
    "                    space = self.space, \n",
    "                    algo=algo,\n",
    "                    max_evals=max_evals, \n",
    "                    trials=trials)\n",
    "\n",
    "        best_params = space_eval(self.space, best)\n",
    "        print ('best:')\n",
    "        print (best_params)\n",
    "        print(\"-\"*20)\n",
    "        print(\"-\"*20)\n",
    "\n",
    "        best_clusters = generate_clusters(self.embeddings, \n",
    "                                         n_neighbors = best_params['n_neighbors'], \n",
    "                                         n_components = best_params['n_components'], \n",
    "                                         min_cluster_size = best_params['min_cluster_size'],\n",
    "                                         cluster_selection_epsilon = best_params['cluster_selection_epsilon'],\n",
    "                                         metric = best_params['metric'],\n",
    "                                         cluster_selection_method = best_params['cluster_selection_method']\n",
    "                                         )\n",
    "\n",
    "        return best_params, best_clusters, trials\n",
    "\n",
    "    def fit(self):\n",
    "        print('*' * 10)\n",
    "        print('TRAINING NOW!')\n",
    "        print('*' * 10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BayesClusterTrainer.generate_clusters\" class=\"doc_header\"><code>BayesClusterTrainer.generate_clusters</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BayesClusterTrainer.generate_clusters</code>(**`embeddings`**, **`min_cluster_size`**, **`cluster_selection_epsilon`**, **`cluster_selection_method`**, **`metric`**, **`n_neighbors`**, **`n_components`**, **`random_state`**=*`42`*)\n",
       "\n",
       "Generate HDBSCAN cluster object after reducing embedding dimensionality with UMAP"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BayesClusterTrainer.generate_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BayesClusterTrainer.objective\" class=\"doc_header\"><code>BayesClusterTrainer.objective</code><a href=\"__main__.py#L47\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BayesClusterTrainer.objective</code>(**`params`**, **`embeddings`**, **`labels`**)\n",
       "\n",
       "Objective function for hyperopt to minimize, which incorporates constraints\n",
       "on the number of clusters we want to identify"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BayesClusterTrainer.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BayesClusterTrainer.score_clusters\" class=\"doc_header\"><code>BayesClusterTrainer.score_clusters</code><a href=\"__main__.py#L72\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BayesClusterTrainer.score_clusters</code>(**`clusters`**, **`y`**)\n",
       "\n",
       "Returns the label count and cost of a given cluster supplied from running hdbscan"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BayesClusterTrainer.score_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"BayesClusterTrainer.train\" class=\"doc_header\"><code>BayesClusterTrainer.train</code><a href=\"__main__.py#L97\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>BayesClusterTrainer.train</code>(**`max_evals`**=*`100`*, **`algo`**=*`suggest`*)\n",
       "\n",
       "Perform bayesian search on hyperopt hyperparameter space to minimize objective function"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BayesClusterTrainer.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "TRAINING NOW!\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "space = {'some_param': range(10)}\n",
    "cost_fn_param = {'a':0.3, 'b': 0.7}\n",
    "emb = np.random.randn(32, 768)\n",
    "labels = np.random.randint(0,1,32)\n",
    "\n",
    "trainer = BayesClusterTrainer(space, cost_fn_param, emb, labels)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(cost_fn_param) == dict\n",
    "assert type(space) == dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
